{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8dcd232-c20c-4cb6-92b1-14de7ab52615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327991e4-05cb-442a-81c2-516c74dc736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_huggingface import HuggingFacePipeline \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a0834-f0b3-4710-aa19-3e0959db3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ab872b-c061-432b-8783-a4fdeb2820ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma 연결\n",
    "CHROMA_HOST = os.getenv(\"CHROMA_HOST\")  # 도커 네트워크에서 컨테이너명\n",
    "CHROMA_PORT = int(os.getenv(\"CHROMA_PORT\"))\n",
    "\n",
    "client = chromadb.HttpClient(\n",
    "    host=CHROMA_HOST,\n",
    "    port=CHROMA_PORT,\n",
    "    settings=Settings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42551e80-1018-4de4-8ab2-10022dd1e5fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 임베딩 모델 지정\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model_kwargs = {'device': 'cuda'} \n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, \n",
    "    model_kwargs=model_kwargs, \n",
    "    encode_kwargs=model_kwargs,\n",
    "    show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad21271-2092-482e-838e-b303f1594547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=financials), Collection(name=topics), Collection(name=news_articles)]\n"
     ]
    }
   ],
   "source": [
    "print(client.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49cb1f3-583a-4df3-a20a-3d2a8b4d11ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5512ae5b080d45d39694c7cdc8713c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/gemma-3-12b-it\" # \"google/gemma-2-9b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",      \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3cca0d6-1fe8-4e17-9568-231d9d5001d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_articles, financials, topics collections들 가져오기(단순 로드)\n",
    "\n",
    "news_articles_collection = Chroma(client=client, collection_name=\"news_articles\", embedding_function=embedding)\n",
    "financials_collection  = Chroma(client=client, collection_name=\"financials\",   embedding_function=embedding)\n",
    "topics_collection = Chroma(client=client, collection_name=\"topics\",   embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c5d4b0-75a8-4c00-ae10-c44ee2242add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    }
   ],
   "source": [
    "########### Inference setting code using RetrievalQAWithSourcesChain ############\n",
    "\n",
    "topk_doc = 10\n",
    "\n",
    "pipe = pipeline(\n",
    "   \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=False,\n",
    "    return_full_text=False,\n",
    "    repetition_penalty=1.1,\n",
    "    #no_repeat_ngram_size=3,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "document_prompt = PromptTemplate(\n",
    "    template=\"{page_content}\",\n",
    "    input_variables=[\"page_content\"]\n",
    ")\n",
    "\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=(\n",
    "        \"아래 컨텐츠만을 근거로 질문에 한국어로 답하세요.\\n\\n\"\n",
    "        \"모르면 모른다고 답하세요.\\n\\n\"\n",
    "        \"질문에 언급된 이름들을 찾을 수 없을 때, 최대한 비슷한 맥락의 단어를 파악하여 질문에 충실하고 정확하게 답하세요.\\n\\n\"\n",
    "        \"답변에 사용된 근거 컨텐츠를 원문 그대로 반드시 덧붙여서 답하세요.\\n\\n\"\n",
    "        \"근거 컨텐츠를 덧붙일 때는 '출처: '와 같은 양식을 따르고, 출처는 컨텐츠 원문을 그대로 출력하세요.\\n\\n\"\n",
    "        \"Question: {question}\\n\\n\" # prompting한 question\n",
    "        \"Contents: {contents}\\n\\n\" \n",
    "        \"Anwser:\" # 모델이 qeustions에 맞게 생성한 응답\n",
    "    ),\n",
    "    input_variables=[\"contents\", \"question\"]\n",
    ")\n",
    "\n",
    "retriever=news_articles_collection.as_retriever(search_kwargs={\"k\": topk_doc}) \n",
    "\n",
    "###### 실행 순서 ######\n",
    "# (1) as_retiever(): DB안에서 question에 맞는 topk 문서 추출(이때, Document 전체 반환)\n",
    "# (2) document_prompt: as_retiever()에서 반환된 documents가 document_prompt에 전달되어 포맷팅(==contents)\n",
    "# (3) qa_prompt: (2)에서 포맷팅된 값(==contents)이 qa_prompt를 거쳐 최종적으로 output을 generation\n",
    "\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type( \n",
    "    llm = llm,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=False,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"document_prompt\": document_prompt,\n",
    "        \"prompt\": qa_prompt,\n",
    "        \"document_variable_name\": \"contents\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c65450-3000-4b07-8486-220631fa0633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba62a700f1304299a04b99b70137d271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "########### company별 keyword 추출: topics_collection ############\n",
    "\n",
    "#추후 사용자의 질문에서 실제 회사명 키워드를 뽑아내는 작업이 필요함(자동화)\n",
    "\n",
    "kw_query = '카카오' #컴퍼니 기준으로 키워드 찾기\n",
    "\n",
    "keyword = kw_query\n",
    "topk = 1\n",
    "\n",
    "kw_topics = topics_collection.similarity_search(keyword, k=topk)\n",
    "\n",
    "company=kw_topics[0].metadata.get('company')\n",
    "com_to_key=kw_topics[0].metadata.get('keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb96a383-5787-4712-a11a-660a716c2bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c54610b5-8095-4b19-8970-1ce8a8820be3', metadata={'company': '카카오', 'doc_type': 'topics', 'keyword': '자료처리'}, page_content='카카오 키워드: 자료처리')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(kw_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf9c42b1-ade3-4ec9-806e-3dc6dff03626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230592/4265163844.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(qa_chain({\"question\": questions}))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3259496774414bbb9995f9ae466a97fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True}. If this is not desired, please set these values explicitly.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "skipping cudagraphs due to skipping cudagraphs due to multiple devices: device(type='cuda', index=0), device(type='cuda', index=3), device(type='cuda', index=1), device(type='cuda', index=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '기업 **카카오**의 기업 신용등급에 영향을 미칠만한 내용을 통해, **자료처리** 업계의 동향을 파악하세요.', 'answer': \"\\n\\n카카오의 기업 신용등급에 영향을 미치는 요소로는 다음과 같은 자료처리 업계 동향을 파악할 수 있습니다.\\n\\n*   **플랫폼 사업 성장 잠재력:** 카카오페이가 카카오톡과 카카오페이 앱을 활용한 플랫폼 접근성과 결제·금융 데이터를 모두 보유하고 있어 플랫폼 사업의 성장 잠재력이 크다는 평가가 있습니다.\\n*   **맞춤형 서비스:** 신한, 하나, 롯데, BC, KB국민카드 등 다양한 카드사와 협력하여 사용자의 일상 속 결제 혜택에 초점을 맞춘 서비스를 제공하고 있습니다. 또한, 신용평가사 정보와 마이데이터, 카카오페이 결제 데이터를 활용해 사용자 맞춤형 카드 추천 서비스와 사전에 신용카드 발급 가능 여부와 한도를 확인해 볼 수 있는 서비스를 제공합니다.\\n*   **소상공인 지원:** 카카오뱅크는 '소상공인 업종 특화 신용평가모형'을 통해 사업자 신용 평가의 변별력을 높이고, 자체 개발한 평가모형을 활용하여 뛰어난 사업역량을 보유한 개인사업자에게 대출 서비스를 제공합니다.\\n*   **AI 기술 활용**: 카카오 AI 서비스 출시 등 IT 업계의 AI 전환이 본격화됨에 따라 Python, 머신러닝, 데이터 분석 등 AI 기초 역량을 학습하는 것이 중요합니다. 또한, KCA에서 수집한 전자파 측정 정보를 상용 앱에서도 확인할 수 있는 API를 개발하여 데이터 활용 능력을 보여주고 있습니다.\\n*   **탄소 감축 노력:** 기보의 탄소 감축 기업 대상 지원과 마찬가지로, 카카오 역시 탄소 배출량 감소 노력을 통해 ESG 경영을 강화할 경우 긍정적인 영향을 받을 수 있습니다.\\n\\n출처:\\n\\n[ⓒ 카카오]카카오, 2분기 영업익 1859억…전년동기比 39%↑ '분기 최대 실적'[조윤정기자] 카카오는 연결 기준 올해 2분기 매출액이 전년 동기보다 1% 증가한 약 2조283억원을 기록했다고 7일 밝혔습니다. 2분기 영업이익은 약 1859억원으로, 전년 같은 기간보다 39% 늘었습니다. 카카오의 올해 2분기 매출액과 영업이익은 모두 분기 기준으로 역대 최대치를 기록했죠\\n\\n[취준생 핵심 체크포인트]✓하반기 채용 정보 수집 강화: 정부 취업자 전망 상향으로 하반기 채용 시장 활성화 예상, 기업별 하반기 채용 공고와 일정 지속 모니터링 필요✓AI 관련 역량 개발 집중: 카카오 AI 서비스 출시 등 IT 업계 AI 전환 본격화, Python, 머신러닝, 데이터 분석 등 AI 기초 역량 즉시 학습 시작✓기업 안전 관리 체계 사전 확인: 제조업 취업 고려 시 산업재해 이력과 안전 조치 현황 면접에서 질문, 고용노동부 사업장 정보 사이트 활용✓글로벌 역량 및 다문화 이해 증진: K컬처 확산과 다문화 사회 진전으로 글로벌 마인드와 다문화 이해능력이 필수 역량으로 부상[키워드 TOP 5]정부 취업자 전망 상향, 카카오 AI 서비스, K푸드 APEC 데뷔, 스마트팜 기술, 하반기 채용 시장, AI PRISM, AI 프리즘\\n\\n이 밖에 카카오뱅크는 개인사업자를 위한 혁신 서비스를 출시하고 있다. 고객 맞춤형 정책자금 대출상품 통합조회 서비스를 비롯해 소상공인 업종 특화 신용평가모형 등이 대표적이다. 카카오뱅크가 자체 소상공인 대안신용평가모형을 적용한 결과 기존 대출 거절 건을 포함한 전체 대출 취급 건 약 7건 중 1건이 추가 승인됐다.카카오뱅크 관계자는 “앞으로도 소상공인의 금융 부담을 덜어주는 실질적인 지원과 편의 서비스로 포용금융을 실천해 나가겠다”고 말했다.김벼리 기자\\n\\n비금융 기반 정보로 대출 심사를 더 정확하게 받을 수 있다\", 'sources': ''}\n"
     ]
    }
   ],
   "source": [
    "########### Output: question(company + keyword with company)에 따른 qa_chain에 결과 출력 코드 ############\n",
    "\n",
    "# 자동화 시 코드 변경 필요\n",
    "questions = f\"기업 **{company}**의 기업 신용등급에 영향을 미칠만한 내용을 통해, **{com_to_key}** 업계의 동향을 파악하세요.\"\n",
    "\n",
    "print(qa_chain({\"question\": questions}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
